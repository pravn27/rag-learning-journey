{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baed828e",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Module Overview\n",
    "This module covers everything you need to know about parsing and ingesting data for RAG systems, from basic text files to complex PDFs and databases. We'll use LangChain v0.3 and explore each technique with practical examples.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- Introduction to Data Ingestion\n",
    "- Text Files (.txt)\n",
    "- PDF Documents\n",
    "- Microsoft Word Documents\n",
    "- CSV and Excel Files\n",
    "- JSON and Structured Data\n",
    "- Web Scraping\n",
    "- Databases (SQL)\n",
    "- Audio and Video Transcripts\n",
    "- Advanced Techniques\n",
    "- Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e92cb",
   "metadata": {},
   "source": [
    "### Introduction to Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3e0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54ac096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed !\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter, \n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(\"Setup completed !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0329b",
   "metadata": {},
   "source": [
    "### Understanding Document Structure in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebadd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document structure:\n",
      "content: LangChain is a framework for developing applications powered by language models. It can be used for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n",
      "metadata: {'source': 'example.txt', 'page': 1, 'author': 'Praveen Shekarappa', 'date_created': '04-01-2026', 'custom_field': 'Any Value'}\n"
     ]
    }
   ],
   "source": [
    "# creating a simple document\n",
    "doc_sample = Document(\n",
    "    page_content = \"LangChain is a framework for developing applications powered by language models. It can be used for chatbots, Generative Question-Answering (GQA), summarization, and much more.\",\n",
    "    metadata = {\n",
    "        \"source\": \"example.txt\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"Praveen Shekarappa\",\n",
    "        \"date_created\": \"04-01-2026\",\n",
    "        \"custom_field\": \"Any Value\"\n",
    "    }\n",
    ")\n",
    "print(\"Document structure:\")\n",
    "print(f\"content: {doc_sample.page_content}\")\n",
    "print(f\"metadata: {doc_sample.metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4912fca",
   "metadata": {},
   "source": [
    "### why metadata is important?\n",
    "#### Metadata provides context about the document, such as its source, author, creation date, and other relevant information. This context can be crucial for various reasons:\n",
    "1. Source Tracking: Knowing where the document came from helps in assessing its credibility and reliability.\n",
    "2. Contextual Understanding: Metadata can provide additional context that aids in interpreting the content correctly.\n",
    "3. Search and Retrieval: Metadata can be used to index and search documents more effectively.\n",
    "4. Filtering: Metadata allows for filtering documents based on specific criteria, such as date range, author, or source\n",
    "5. Compliance and Auditing: In regulated industries, metadata can help track document history for compliance purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39d1787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638c5ab",
   "metadata": {},
   "source": [
    "### Simplest case on Text files (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822f920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple text file\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "\"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"âœ… Sample text files created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0dc1a1",
   "metadata": {},
   "source": [
    "### TextLoader - Read Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c584e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "Content preview: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for ...\n",
      "Metadata: {'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "# Load text files from the directory - read single file\n",
    "loader = TextLoader(file_path=\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "# print(type(documents))\n",
    "# print(documents)\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"Content preview: {documents[0].page_content[:100]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fc0f7",
   "metadata": {},
   "source": [
    "### Directory Loader - Multiple text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b9e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1580.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded from directory: 2\n",
      "\n",
      "Document 1:\n",
      "  Source: data/text_files/python_intro.txt\n",
      "  Length: 489 characters\n",
      "\n",
      "Document 2:\n",
      "  Source: data/text_files/machine_learning.txt\n",
      "  Length: 575 characters\n",
      "\n",
      "ðŸ“Š DirectoryLoader Characteristics:\n",
      "âœ… Advantages:\n",
      "  - Loads multiple files at once\n",
      "  - Supports glob patterns\n",
      "  - Progress tracking\n",
      "  - Recursive directory scanning\n",
      "\n",
      "âŒ Disadvantages:\n",
      "  - All files must be same type\n",
      "  - Limited error handling per file\n",
      "  - Can be memory intensive for large directories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# Load all text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    path = \"data/text_files\",\n",
    "    glob = \"**/*.txt\", # pattern to match text files\n",
    "    loader_cls = TextLoader, # specify the loader class\n",
    "    loader_kwargs = {\"encoding\": \"utf-8\"},\n",
    "    show_progress = True\n",
    ")\n",
    "\n",
    "all_documents = dir_loader.load()\n",
    "print(f\"Total documents loaded from directory: {len(all_documents)}\")\n",
    "for i, doc in enumerate(all_documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
    "\n",
    "# ðŸ“Š Analysis\n",
    "print(\"\\nðŸ“Š DirectoryLoader Characteristics:\")\n",
    "print(\"âœ… Advantages:\")\n",
    "print(\"  - Loads multiple files at once\")\n",
    "print(\"  - Supports glob patterns\")\n",
    "print(\"  - Progress tracking\")\n",
    "print(\"  - Recursive directory scanning\")\n",
    "\n",
    "print(\"\\nâŒ Disadvantages:\")\n",
    "print(\"  - All files must be same type\")\n",
    "print(\"  - Limited error handling per file\")\n",
    "print(\"  - Can be memory intensive for large directories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0be65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
